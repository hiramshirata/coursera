{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "7a2aba773768f3028cfd68a875299321972753977854c0935b697eedbb83aab0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n"
     ]
    }
   ],
   "source": [
    "import trax\n",
    "from trax import layers as tl\n",
    "import trax.fastmath.numpy as np\n",
    "import numpy\n",
    "\n",
    "# Setting random seeds\n",
    "numpy.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([ 0, 10], dtype=uint32)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "trax.supervised.trainer_lib.init_random_number_generators(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcao para normalizar o vetor\n",
    "\n",
    "def normalize(x):\n",
    "    return x / np.sqrt(np.sum(x * x, axis=-1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! verificar sintaxe para chamar funcao, via lambda?\n",
    "\n",
    "vocab_size = 1000\n",
    "model_dimension = 128\n",
    "\n",
    "# Define the LSTM model\n",
    "LSTM = tl.Serial(\n",
    "        tl.Embedding(vocab_size=vocab_size, d_feature=model_dimension),\n",
    "        tl.LSTM(model_dimension),\n",
    "        tl.Mean(axis=1),\n",
    "        tl.Fn('Normalize', lambda x: normalize(x))\n",
    "    )\n",
    "\n",
    "# Use the Parallel combinator to create a Siamese model out of the LSTM \n",
    "Siamese = tl.Parallel(LSTM, LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Siamese model:\n\nTotal layers: 2\n\n========\nParallel.sublayers_0: Serial[\n  Embedding_1000_128\n  LSTM_128\n  Mean\n  Normalize\n]\n\n========\nParallel.sublayers_1: Serial[\n  Embedding_1000_128\n  LSTM_128\n  Mean\n  Normalize\n]\n\nDetail of LSTM models:\n\nTotal layers: 4\n\n========\nSerial.sublayers_0: Embedding_1000_128\n\n========\nSerial.sublayers_1: LSTM_128\n\n========\nSerial.sublayers_2: Mean\n\n========\nSerial.sublayers_3: Normalize\n\n"
     ]
    }
   ],
   "source": [
    "def show_layers(model, layer_prefix):\n",
    "    print(f\"Total layers: {len(model.sublayers)}\\n\")\n",
    "    for i in range(len(model.sublayers)):\n",
    "        print('========')\n",
    "        print(f'{layer_prefix}_{i}: {model.sublayers[i]}\\n')\n",
    "\n",
    "print('Siamese model:\\n')\n",
    "show_layers(Siamese, 'Parallel.sublayers')\n",
    "\n",
    "print('Detail of LSTM models:\\n')\n",
    "show_layers(LSTM, 'Serial.sublayers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-- Inputs --\nv1 : [1. 2. 3.]\nv2 : [-1.  -2.   3.5] \n\n-- Outputs --\ncosine similarity : 0.35391919864828275\n"
     ]
    }
   ],
   "source": [
    "# Two vector example\n",
    "# Input data\n",
    "print(\"-- Inputs --\")\n",
    "v1 = np.array([1, 2, 3], dtype=float)\n",
    "v2 = np.array([-1, -2, 3.5])  # notice the 3rd element is offset by 0.5\n",
    "### START CODE HERE ###\n",
    "# Try modifying the vector v2 to see how it impacts the cosine similarity\n",
    "# v2 = v1                   # identical vector\n",
    "# v2 = v1 * -1              # opposite vector\n",
    "# v2 = np.array([0,-42,1])  # random example\n",
    "### END CODE HERE ###\n",
    "print(\"v1 :\", v1)\n",
    "print(\"v2 :\", v2, \"\\n\")\n",
    "\n",
    "# Similarity score\n",
    "def cosine_similarity(v1, v2):\n",
    "    numerator = np.dot(v1, v2)\n",
    "    denominator = np.sqrt(np.dot(v1, v1)) * np.sqrt(np.dot(v2, v2))\n",
    "    return numerator / denominator\n",
    "\n",
    "print(\"-- Outputs --\")\n",
    "print(\"cosine similarity :\", cosine_similarity(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-- Inputs --\nv1 :\n[[ 1  2  3]\n [ 9  8  7]\n [-1 -4 -2]\n [ 1 -7  2]] \n\nv2 :\n[[-0.93013134  4.05654816  3.45726026]\n [ 9.89027523  5.72679558  7.27027376]\n [ 1.969074   -6.15960977 -5.95545656]\n [-2.48674459 -6.46785967  6.76993466]] \n\nbatch sizes match : True \n\n-- Outputs --\noption 1 : loop\n[[ 0.86714979  0.85149226 -0.85780846  0.13483214]\n [ 0.64069039  0.9844001  -0.59816176 -0.19812923]\n [-0.89580583 -0.76263556  0.85836066  0.33379055]\n [-0.5636852  -0.15729734  0.5135357   0.79124949]] \n\noption 2 : vec norm & dot product\n[[ 0.86714979  0.85149226 -0.85780846  0.13483214]\n [ 0.64069039  0.9844001  -0.59816176 -0.19812923]\n [-0.89580583 -0.76263556  0.85836066  0.33379055]\n [-0.5636852  -0.15729734  0.5135357   0.79124949]] \n\noutputs are the same : True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# !!! numpy vertical stacking vectors\n",
    "\n",
    "# Two batches of vectors example\n",
    "# Input data\n",
    "print(\"-- Inputs --\")\n",
    "v1_1 = np.array([1, 2, 3])\n",
    "v1_2 = np.array([9, 8, 7])\n",
    "v1_3 = np.array([-1, -4, -2])\n",
    "v1_4 = np.array([1, -7, 2])\n",
    "v1 = np.vstack([v1_1, v1_2, v1_3, v1_4])\n",
    "print(\"v1 :\")\n",
    "print(v1, \"\\n\")\n",
    "v2_1 = v1_1 + np.random.normal(0, 2, 3)  # add some noise to create approximate duplicate\n",
    "v2_2 = v1_2 + np.random.normal(0, 2, 3)\n",
    "v2_3 = v1_3 + np.random.normal(0, 2, 3)\n",
    "v2_4 = v1_4 + np.random.normal(0, 2, 3)\n",
    "v2 = np.vstack([v2_1, v2_2, v2_3, v2_4])\n",
    "print(\"v2 :\")\n",
    "print(v2, \"\\n\")\n",
    "\n",
    "# Batch sizes must match\n",
    "b = len(v1)\n",
    "print(\"batch sizes match :\", b == len(v2), \"\\n\")\n",
    "\n",
    "# Similarity scores\n",
    "print(\"-- Outputs --\")\n",
    "# Option 1 : nested loops and the cosine similarity function\n",
    "sim_1 = np.zeros([b, b])  # empty array to take similarity scores\n",
    "# Loop\n",
    "for row in range(0, sim_1.shape[0]):\n",
    "    for col in range(0, sim_1.shape[1]):\n",
    "        sim_1[row, col] = cosine_similarity(v1[row], v2[col])\n",
    "\n",
    "print(\"option 1 : loop\")\n",
    "print(sim_1, \"\\n\")\n",
    "\n",
    "# Option 2 : vector normalization and dot product\n",
    "def norm(x):\n",
    "    return x / np.sqrt(np.sum(x * x, axis=1, keepdims=True))\n",
    "\n",
    "sim_2 = np.dot(norm(v1), norm(v2).T)\n",
    "\n",
    "print(\"option 2 : vec norm & dot product\")\n",
    "print(sim_2, \"\\n\")\n",
    "\n",
    "# Check\n",
    "print(\"outputs are the same :\", np.allclose(sim_1, sim_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-- Inputs --\nsim :\n[[ 0.9 -0.8  0.3 -0.5]\n [-0.4  0.5  0.1 -0.1]\n [ 0.3  0.1 -0.4 -0.8]\n [-0.5 -0.2 -0.7  0.5]]\nshape : (4, 4) \n\nsim_ap :\n[[ 0.9  0.   0.   0. ]\n [ 0.   0.5  0.   0. ]\n [ 0.   0.  -0.4  0. ]\n [ 0.   0.   0.   0.5]] \n\nsim_an :\n[[ 0.  -0.8  0.3 -0.5]\n [-0.4  0.   0.1 -0.1]\n [ 0.3  0.1  0.  -0.8]\n [-0.5 -0.2 -0.7  0. ]] \n\n-- Outputs --\nmean_neg :\n[[-0.33333333]\n [-0.13333333]\n [-0.13333333]\n [-0.46666667]] \n\nclosest_neg :\n[[ 0.3]\n [ 0.1]\n [-0.8]\n [-0.2]] \n\n"
     ]
    }
   ],
   "source": [
    "# Hardcoded matrix of similarity scores\n",
    "sim_hardcoded = np.array(\n",
    "    [\n",
    "        [0.9, -0.8, 0.3, -0.5],\n",
    "        [-0.4, 0.5, 0.1, -0.1],\n",
    "        [0.3, 0.1, -0.4, -0.8],\n",
    "        [-0.5, -0.2, -0.7, 0.5],\n",
    "    ]\n",
    ")\n",
    "\n",
    "sim = sim_hardcoded\n",
    "### START CODE HERE ###\n",
    "# Try using different values for the matrix of similarity scores\n",
    "# sim = 2 * np.random.random_sample((b,b)) -1   # random similarity scores between -1 and 1\n",
    "# sim = sim_2                                   # the matrix calculated previously\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Batch size\n",
    "b = sim.shape[0]\n",
    "\n",
    "print(\"-- Inputs --\")\n",
    "print(\"sim :\")\n",
    "print(sim)\n",
    "print(\"shape :\", sim.shape, \"\\n\")\n",
    "\n",
    "# Positives\n",
    "# All the s(A,P) values : similarities from duplicate question pairs (aka Positives)\n",
    "# These are along the diagonal\n",
    "sim_ap = np.diag(sim)\n",
    "print(\"sim_ap :\")\n",
    "print(np.diag(sim_ap), \"\\n\")\n",
    "\n",
    "# Negatives\n",
    "# all the s(A,N) values : similarities the non duplicate question pairs (aka Negatives)\n",
    "# These are in the off diagonals\n",
    "sim_an = sim - np.diag(sim_ap)\n",
    "print(\"sim_an :\")\n",
    "print(sim_an, \"\\n\")\n",
    "\n",
    "print(\"-- Outputs --\")\n",
    "# Mean negative\n",
    "# Average of the s(A,N) values for each row\n",
    "mean_neg = np.sum(sim_an, axis=1, keepdims=True) / (b - 1)\n",
    "print(\"mean_neg :\")\n",
    "print(mean_neg, \"\\n\")\n",
    "\n",
    "# Closest negative\n",
    "# Max s(A,N) that is <= s(A,P) for each row\n",
    "mask_1 = np.identity(b) == 1            # mask to exclude the diagonal\n",
    "mask_2 = sim_an > sim_ap.reshape(b, 1)  # mask to exclude sim_an > sim_ap -- compares for each row to the column vector sim_ap\n",
    "mask = mask_1 | mask_2                  # operador ou\n",
    "sim_an_masked = np.copy(sim_an)         # create a copy to preserve sim_an\n",
    "sim_an_masked[mask] = -2                # where true it receives the minus 2 ... so the max function can retrieve only the second best values\n",
    "\n",
    "closest_neg = np.max(sim_an_masked, axis=1, keepdims=True)\n",
    "print(\"closest_neg :\")\n",
    "print(closest_neg, \"\\n\")"
   ]
  }
 ]
}